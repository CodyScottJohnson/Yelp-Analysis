---
output: 
  html_notebook: 
    number_sections: yes
---
<img src="img/yelp-logo.png"></img>
```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
list.of.packages <- c('tidyr','plotly','mlbench','caret','ROCR','e1071','ggplot2','dataPreparation','corrplot','sjPlot','sjmisc','sqldf')
new.packages <- list.of.packages[!(list.of.packages %in% installed.packages()[,"Package"])]
if(length(new.packages)) install.packages(new.packages)
lapply(list.of.packages, require, character.only=TRUE)
```

### Read in Data



```{r data}
data<-read.csv("data/yelp_data_reformat.csv")
```

## Filter to look at unique businesses

>Filtering the data down so we have one row per business and don't risk double counting or skewing results while analyzing the affect of business characteristics on their average rateing



```{r}
business_data <- data %>%
    select(Business...Id,Business...Stars,Business...Review.Count,Business...Wi.Fi,Business...Waiter.Service,Business...Take.out,Business...Price.Range,Business...Parking,Business...Noise.Level,Business...Good.For.Kids,Business...Accepts.Credit.Cards,Business...Ages.Allowed,Business...Has.TV,Business...Categories) %>%
    mutate(Price.Range = factor(Business...Price.Range),
           Business...Review.Count = as.numeric(Business...Review.Count)) %>%
    distinct()


head(business_data)
```
### Clean Data
>Perform some basic data cleaning and validations

```{r}
constant_cols <- whichAreConstant(business_data)
double_cols <- whichAreInDouble(business_data)
bijections_cols <- whichAreBijection(business_data)
```

### Key metrics
> Perhaps more interesting than reviews to both individual business and yelp as a platform  is how reviews drive traffic and patronage. While the connection may seem obvious between high reviews and patronage/interaction it would be ideal to find a metric that was a closer proxy for actual interaction. With that in mind I'd like to look at the number of reviews a dependent variable as perhaps a closer proxy for how many people are actually visiting the establishment.

```{r}
g<- ggplot(business_data,aes(x=Business...Review.Count)) +
  geom_density(alpha=.3,fill="#D32323",color="#D32323")
ggplotly(g)

```
```{r}
g2<-ggplot(business_data,aes(x=Business...Stars)) +
  geom_histogram(alpha=.3,fill="#D32323",color="#D32323")
ggplotly(g2)
```

## Looking at Number of Reviews

```{r}
business_reg <- lm(Business...Review.Count~Price.Range + Business...Stars + Business...Wi.Fi+Business...Noise.Level + Price.Range*Business...Wi.Fi+ Business...Good.For.Kids+Business...Has.TV,data=business_data)

summary(business_reg)

```
```{r}
plot_model(business_reg)
```
```{r}
business_reg <- lm(Business...Review.Count~Price.Range + Business...Stars + Business...Wi.Fi+Business...Noise.Level + Price.Range*Business...Wi.Fi,data=business_data)

summary(business_reg)

```
```{r}
plot_model(business_reg)
```
## Looking at Rating

```{r}
business_reg <- lm(Business...Stars~Price.Range  + Business...Wi.Fi+Business...Noise.Level,data=business_data)

summary(business_reg)

```
```{r}
plot_model(business_reg)
```

## Momentum of Ratings
> We want to look at the affect a businesses current rating has on it's ability to attract new customers and it's ability to improve it's overall rating. There are definately better ways to do this but for now at each point of time for which we have info we calculate the average rating at that point, the number of reviews the recieve after that point and their average rating after that point.
```{r}
temp_data <- data %>%
    mutate(Review...Date = as.Date(Review...Date, format = "%m/%d/%y"))
```
```{r,eval = FALSE}

drops <- c("Business...Good.for.Kids")
temp_data <- temp_data[ , !(names(temp_data) %in% drops)]
p<-sqldf("select a.'Business...Stars',a.'Review...Date',a.'Business...Review.Count',
            (select avg(a.'Review...Stars')
                               from temp_data b
                                where b.'Review...Date' <= a.'Review...Date' and b.'Business...Id' = a.'Business...Id') as 'AvgReviewAtDate',
 (select count(*)
                               from temp_data b
                                where b.'Review...Date' >= a.'Review...Date' and b.'Business...Id' = a.'Business...Id') as 'ReviewsAftertDate',
 (select avg(a.'Review...Stars')
                               from temp_data b
                                where b.'Review...Date' > a.'Review...Date' and b.'Business...Id' = a.'Business...Id') as 'AvgReviewAftertDate'
       from temp_data a
        group by a.'Business...Stars',a.'Review...Date',a.'Business...Review.Count'")


```
```{r,eval = FALSE}
head(p)
```
```{r,eval = FALSE}
p$review_cat <- cut(x = p$AvgReviewAtDate, # x is the vector we want to split.
                  breaks = quantile(p$AvgReviewAtDate, 
                                    probs = seq(0, 1, .1)), # breaks defines the
                  # where we want to split it. We use the quantile function to 
                  # define those splits by equal portions, in this case 20%
                  include.lowest = T)

``
```{r,eval = FALSE}
ggplot(p,aes(x=AvgReviewAftertDate,fill=review_cat,color=review_cat)) + 
  geom_violin()

``
```{r,eval = FALSE}
ggplot(p,aes(x=AvgReviewAftertDate,fill=review_cat,color=review_cat)) + 
  geom_boxplot()

``
```{r,eval = FALSE}
ggplot(p,aes(x=ReviewsAftertDate,fill=review_cat,color=review_cat)) + 
  geom_boxplot()

``
```{r,eval = FALSE}
ggplot(p,aes(x=AvgReviewAtDate,y=ReviewsAftertDate,size=(Business...Review.Count-ReviewsAftertDate))) + 
  geom_point(alpha=.2,fill="#D32323",color="#D32323")

``
```{r,eval = FALSE}
ggplot(p,aes(x=AvgReviewAtDate,y=AvgReviewAftertDate,size=(Business...Review.Count-ReviewsAftertDate))) + 
  geom_point(alpha=.2,fill="#D32323",color="#D32323")

``
